###Intro to Cypress

All the information you ever needed, including setting up an account, can be found here
https://wiki.hpc.tulane.edu/trac/wiki/cypress#CodingonCypress

* Please make sure you have reviwed the cypress wiki before Thursday and in particular, how to submit job requests (https://wiki.hpc.tulane.edu/trac/wiki/cypress/using#SubmittingJobsonCypress)

Once your account is set up, logging in is easy. Replace "eenbody" with your Tulane username and then type your Tulane password when prompted.

```bash
ssh eenbody@cypress1.tulane.edu
```

###pyRAD Tutorial on cypress

Now we can run the pyRAD tutorial on the cluster (http://nbviewer.jupyter.org/gist/dereneaton/1f661bfb205b644086cc/tutorial_RAD_3.0.ipynb)

* Open a new terminal window (not on cypress) and download the pyRAD RAD tutorial data into your current directory

```bash
wget -q dereneaton.com/downloads/simRADs.zip
unzip simRADs.zip
```

* Next, we're going to copy the folder over to your directory on cypress. Just replace eenbody with your username. 
* You can also transfer the zipped file if unzipping it did not create a new directory, and then unzip that file in your cypress directory.

```bash
scp ./simRADs/ eenbody@cypress1.tulane.edu:/home/eenbody
```

* Either log into cypress or return to the window where you had cypress open. 
* Navigate into the simRADs directory. 
* Create a new job ticket file

```bash
nano pyrad_n.srun
```

* The contents should be this (make sure you understand what each line means, via the wiki above). pyRAD is already installed as a module on cypress and to run it you must load it in (module load pyrad) and execute it using pyrad (lowercase). 

```bash

#!/bin/bash
#SBATCH --job-name=OneHourJob ### Job Name
#SBATCH --nodes=1             ### Node count required for the job
#SBATCH --ntasks-per-node=1   ### Nuber of tasks to be launched per Node

module load pyrad

pyrad -n
```

* Execute the command using sbatch

```bash
sbatch pyrad_n.srun
```

* Just like running this on your desktop, if this ran successfully, you should have a params.txt file in your directory.

* On cypress, you should have no issues editing the params.txt file using sed

```bash
%%bash
sed -i '/## 7. /c\2                   ## 7. N processors... ' params.txt
sed -i '/## 10. /c\.85                ## 10. lowered clust thresh... ' params.txt
sed -i '/## 14. /c\c85m4p3            ## 14. outprefix... ' params.txt
sed -i '/## 24./c\8                   ## 24. maxH raised ... ' params.txt
sed -i '/## 30./c\*                   ## 30. all output formats... ' params.txt
```

* Now, create a new job request file called pyrad1.srun with the following info, then run it with sbatch. You should be able to do the same with all 7 steps of the RAD tutorial. 

```bash
#!/bin/bash
#SBATCH --job-name=OneHourJob ### Job Name
#SBATCH --nodes=1             ### Node count required for the job
#SBATCH --ntasks-per-node=1   ### Nuber of tasks to be launched per Node

module load pyrad

pyrad -p params.txt -s 1
```

####Running pyRAD with a real dataset

We are going to use pyRAD to call SNPs on Sara L's dataset from her work with jacana. These are data generated by a slightly different method than that above, as her samples were sequenced by genoytpe by sequencing (GBS) methods. As far as pyRAD is concerned, things won't change that much. 

* First, you will need to copy the raw data to your lab's project folder. Only one member per lab should do this. You will also need to physically go to the derryberry lab to initiate this transfer. I will send instructions by email about the password.

* Once you are at the computer, open terminal and login to cypress. You want to find your way to the lustre project folder for your lab and make a directory for jacanas. For example for the karubian lab see below. You should only have permission to access your workgroup's folder.

```bash
cd /lustre/project/jk
mkdir Jacana_Raw_Reads
```

* Now that we are here, lets transfer those files. They are large files and total ~60gb, so using the "scp" command is a bit unwieldy as it was built for smaller files. Instead we will use bcbp. You will want to specify the login information of your local computer. The following example is for the Blum lab login.

```bash
bbcp -zv -r "blumlab@eeb-globus.tulane.edu:/Volumes/LaCie/Jacana_GBS_Raw_Reads" Jacana_Raw_Reads/
```

-v stands for verbose 
-r is for recursive (copies all files in the directory)
-z this is used in this case to transfer files from another ip (i.e. from the mac tower), but you wouldn't need it if you were sitting at the tower instead I believe..

You should get some output like this (each line comes in slowly)

```bash
bbcp: Indexing files to be copied...
bbcp: Copying 5 files and 0 links in 1 directory.
File Jacana_Raw_Reads/Jacana GBS Raw Reads/.DS_Store created; 6148 bytes at 255.8 KB/s
File Jacana_Raw_Reads/Jacana GBS Raw Reads/C6RL0ANXX_1_fastq created; 67982686805 bytes at 76.8 MB/s
File Jacana_Raw_Reads/Jacana GBS Raw Reads/C6RL0ANXX_1_fastq.gz created; 18058122029 bytes at 67.9 MB/s
File Jacana_Raw_Reads/Jacana GBS Raw Reads/C6RL0ANXX_2_fastq.gz created; 17324891025 bytes at 67.2 MB/s
File Jacana_Raw_Reads/Jacana GBS Raw Reads/C6RL0ANXX_3_fastq.gz created; 17453590465 bytes at 64.3 MB/s
5 files copied at effectively 71.7 MB/s\
```

* I'm not sure how long mine took, but at least half an hour I think. Now you are ready to use cypress to dig through this dataset!

Now, we're ready to run pyrad. 

* First, we need to create a new params file

```bash
module load pyrad
pyrad -n
```

* You should see a new file, params.txt. 

For step 1, demultiplexing, we need to edit this params file to read our fastq file for plate 1 and provide it with a barcodes file.

```bash
==** parameter inputs for pyRAD version 3.0.66  **======================== affected step ==
./                        ## 1. Working directory                                 (all)
./C6RL0ANXX_1_fastq.gz              ## 2. Loc. of non-demultiplexed files (if not line 18)  (s1)
./jacana1.barcodes              ## 3. Loc. of barcode file (if not line 18)             (s1)
vsearch                   ## 4. command (or path) to call vsearch (or usearch)    (s3,s6)
muscle                    ## 5. command (or path) to call muscle                  (s3,s7)
TGCAG                     ## 6. Restriction overhang (e.g., C|TGCAG -> TGCAG)     (s1,s2)
20                         ## 7. N processors (parallel)                           (all)
6                         ## 8. Mindepth: min coverage for a cluster              (s4,s5)
4                         ## 9. NQual: max # sites with qual < 20 (or see line 20)(s2)
.88                       ## 10. Wclust: clustering threshold as a decimal        (s3,s6)
rad                       ## 11. Datatype: rad,gbs,pairgbs,pairddrad,(others:see docs)(all)
4                         ## 12. MinCov: min samples in a final locus             (s7)
3                         ## 13. MaxSH: max inds with shared hetero site          (s7)
c88d6m4p3                 ## 14. Prefix name for final output (no spaces)         (s7)
```

Now, we need to create a script to run step one. I've called my script pyrad_1.srun.

```bash
#!/bin/bash
#SBATCH --qos=normal
#SBATCH --job-name=sara_pyrad_s1.1 ### Job Name
#SBATCH --nodes=1             ### Node count required for the job
#SBATCH --ntasks-per-node=20   ### Nuber of tasks to be launched per Node
#SBATCH --output=jacanas1.1output.out
#SBATCH --error=jacana1error.err

module load pyrad

pyrad -p params.txt -s 1
```

Continue running step 1 for plates 2 and 3 by modifying your params.t file and running new scripts or editing the first one.
